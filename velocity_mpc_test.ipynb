{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from NonlinearController.mpc_utils import *\n",
    "from NonlinearController.controllers import *\n",
    "from NonlinearController.model_utils import *\n",
    "from NonlinearController.lpv_embedding import *\n",
    "from NonlinearController.systems import UnbalancedDisc\n",
    "import deepSI\n",
    "import qpsolvers as qp\n",
    "import torch\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################  Utility functions  #######################\n",
    "\n",
    "def differenceVector(X_1, nx):\n",
    "    return X_1[nx:] - X_1[:-nx]\n",
    "\n",
    "def extendABC(list_A, list_B, list_C, nx, ny):\n",
    "    nz = nx+ny\n",
    "    list_ext_A = np.zeros((nz*Nc,nz))\n",
    "    list_ext_B = np.zeros((nz*Nc,nu))\n",
    "    list_ext_C = np.zeros((ny*Nc,nz))\n",
    "\n",
    "    for i in range(Nc):\n",
    "        list_ext_A[(i*nz):(i*nz+ny),:ny] = np.eye(ny)\n",
    "        list_ext_A[(i*nz):(i*nz+ny),ny:nz] = list_C[(ny*i):(ny*i+ny),:]\n",
    "        list_ext_A[(i*nz+ny):(i*nz+nz),ny:nz] = list_A[(nx*i):(nx*i+nx),:]\n",
    "\n",
    "    for i in range(Nc):\n",
    "        list_ext_B[(i*nz+ny):(i*nz+nz),:] = list_B[(nx*i):(nx*i+nx),:]\n",
    "\n",
    "    for i in range(Nc):\n",
    "        list_ext_C[(i*ny):(i*ny+ny),:ny] = np.eye(ny)\n",
    "        list_ext_C[(i*ny):(i*ny+ny),ny:nz] = list_C[(ny*i):(ny*i+ny),:]\n",
    "    \n",
    "    return list_ext_A, list_ext_B, list_ext_C\n",
    "\n",
    "def extendState(Y_1, dX0, nx, ny):\n",
    "    nz = nx+ny\n",
    "    Z0 = np.zeros((Nc*nz,1))\n",
    "\n",
    "    for i in range(Nc):\n",
    "        Z0[(nz*i):(nz*i+ny),:] = Y_1[ny*i:(ny*i+ny),:]\n",
    "        Z0[(nz*i+ny):(nz*i+nz),:] = dX0[nx*i:(nx*i+nx),:]\n",
    "\n",
    "    return Z0\n",
    "\n",
    "def decodeState(Z0, nx, ny):\n",
    "    nz = nx+ny\n",
    "    Y_1 = np.zeros((Nc*ny,1))\n",
    "    dX0 = np.zeros((Nc*nx,1))\n",
    "\n",
    "    for i in range(Nc):\n",
    "        Y_1[ny*i:(ny*i+ny),:] = Z0[(nz*i):(nz*i+ny),:]\n",
    "        dX0[nx*i:(nx*i+nx),:] = Z0[(nz*i+ny):(nz*i+nz),:]\n",
    "\n",
    "    return Y_1, dX0\n",
    "\n",
    "def extendReference(reference, nx, ny, Nc):\n",
    "    nz = nx+ny\n",
    "\n",
    "    r = np.zeros((Nc*nz,1))\n",
    "\n",
    "    for i in range(Nc):\n",
    "        r[nz*i,0] = reference[i]\n",
    "\n",
    "    return r\n",
    "\n",
    "def randomLevelReference(Nsim, nt_range, level_range):\n",
    "    x_reference_list = np.array([])\n",
    "    Nsim_remaining = Nsim\n",
    "    while True:\n",
    "        Nsim_steps = random.randint(nt_range[0],nt_range[1])\n",
    "        Nsim_remaining = Nsim_remaining - Nsim_steps\n",
    "        x_reference_list = np.hstack((x_reference_list, np.ones(Nsim_steps)*random.randint(level_range[0]*10,level_range[1]*10)/10))\n",
    "\n",
    "        if Nsim_remaining <= 0:\n",
    "            x_reference_list = x_reference_list[:Nsim]\n",
    "            break\n",
    "    return x_reference_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################  System  #######################\n",
    "dt = 0.1\n",
    "system = UnbalancedDisc(dt=dt, sigma_n=[0.0])\n",
    "system.reset_state()\n",
    "\n",
    "##################  MPC variable specification  #######################\n",
    "model = deepSI.load_system(\"NonlinearController/trained_models/unbalanced/ObserverUnbalancedDisk_dt01_nab_4_SNR_30_e250\")\n",
    "Nc=10; nr_iterations = 4; nr_sim_steps = 450\n",
    "\n",
    "w_min = -4; w_max = 4\n",
    "q_min = [-1.2, -10000, -10000]; q_max = [1.2, 10000, 10000] # augmented with the velocity states\n",
    "w0 = 0; q0 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference = randomLevelReference(nr_sim_steps+Nc, [20,25], [-1.2,1.2])\n",
    "# reference = np.ones(nr_sim_steps+Nc)*1.2\n",
    "# reference = deepSI.deepSI.exp_design.multisine(nr_sim_steps+Nc, pmax=10, n_crest_factor_optim=20)/1.4\n",
    "# reference = np.hstack((np.zeros(20), 0.8*np.ones(nr_sim_steps+Nc-20)))\n",
    "# amp = 0.7; reference = np.tile(np.hstack((-amp*np.ones(30), amp*np.ones(30))), 15)\n",
    "\n",
    "# np.save(\"NonlinearController/references/setPoints.npy\", reference)\n",
    "# np.save(\"NonlinearController/references/setPoints_Range30_50.npy\", reference)\n",
    "reference = np.load(\"NonlinearController/references/setPoints.npy\")\n",
    "# plt.plot(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################  Offline Computation  #######################\n",
    "nx = model.nx\n",
    "nu = model.nu if model.nu is not None else 1\n",
    "ny = model.ny if model.ny is not None else 1\n",
    "nz = nx+ny\n",
    "ne = 1\n",
    "\n",
    "# initialize objective function matrices\n",
    "R = np.eye(nu)*1; Q = np.matrix('200,0,0;0,500,0;0,0,10')#Q = np.eye(nz)# these are user defined\n",
    "Psi = get_Psi(Nc, R)\n",
    "Omega = get_Omega(Nc, Q)\n",
    "# extended objective matrices for soft constraints\n",
    "e_lambda = 1000000 # weighting of minimizing e in objective function\n",
    "Ge = np.zeros((Nc*nu+ne,Nc*nu+ne)) \n",
    "Ge[-ne:,-ne:] = e_lambda\n",
    "\n",
    "embedder = velocity_lpv_embedder_autograd(model, Nc, n_stages=20)\n",
    "\n",
    "# normalize initial input and output\n",
    "norm = model.norm\n",
    "u0 = norm_input(w0, norm)\n",
    "y0 = norm_output(q0, norm)\n",
    "\n",
    "# initialize observer history input and output\n",
    "nb = model.nb\n",
    "uhist = torch.ones((1,nb))*u0\n",
    "na = model.na\n",
    "yhist = torch.ones((1,na+1))*y0\n",
    "\n",
    "# initial predicted states, input, and output\n",
    "X_1 = np.tile(model.encoder(uhist,yhist).detach().numpy(),Nc+1).T\n",
    "U_1 = np.ones((Nc+1)*nu)[np.newaxis].T*u0\n",
    "Y_1 = np.ones((Nc)*ny)[np.newaxis].T *y0\n",
    "\n",
    "# determine constraint matrices\n",
    "u_min = norm_input(w_min, norm); u_max = norm_input(w_max, norm)\n",
    "y_min = norm_output(q_min, norm); y_max = norm_output(q_max, norm)\n",
    "D, E, M, c = getDEMc(y_min, y_max, u_min, u_max, Nc, nz, nu)\n",
    "Lambda = np.tril(np.ones((Nc,Nc)),0)\n",
    "\n",
    "##################  Logging  #######################\n",
    "log_q = np.zeros((ny,nr_sim_steps))\n",
    "log_w = np.zeros((nu,nr_sim_steps))\n",
    "log_e = np.zeros((ne,nr_sim_steps))\n",
    "log_iterations = np.zeros((1,nr_sim_steps))\n",
    "log_comp_t = np.zeros((4, nr_sim_steps*nr_iterations))\n",
    "\n",
    "offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################  Online Computation  #######################\n",
    "\n",
    "#++++++++++++++++++ start simulation step +++++++++++++++++++++++\n",
    "for k in range(nr_sim_steps):\n",
    "    # extend normalized reference to form of extended state\n",
    "    r = extendReference(norm_output(reference[k:k+Nc], norm), nx, ny, Nc)\n",
    "    \n",
    "    #++++++++++++++++++ start iteration +++++++++++++++++++++++\n",
    "    for iteration in range(nr_iterations):\n",
    "        # determine predicted velocity states and output\n",
    "        dX0 = differenceVector(X_1, nx)\n",
    "        dU0 = differenceVector(U_1, nu)\n",
    "        # determine extended state from predicted output and velocity states\n",
    "        Z0 = extendState(Y_1, dX0, nx, ny)\n",
    "\n",
    "        # determine lpv state space dependencies\n",
    "        component_start = time.time()\n",
    "\n",
    "        list_A, list_B, list_C = embedder(X_1, U_1)\n",
    "        list_ext_A, list_ext_B, list_ext_C = extendABC(list_A, list_B, list_C, nx, ny)\n",
    "\n",
    "        log_comp_t[0, nr_iterations*k + iteration] = log_comp_t[0, nr_iterations*k + iteration] + time.time() - component_start\n",
    "\n",
    "        # describe optimization problem\n",
    "        component_start = time.time()\n",
    "\n",
    "        Phi = get_Phi(list_ext_A, Nc, nz)\n",
    "        Gamma = get_Gamma(list_ext_A, list_ext_B, Nc, nz, nu)\n",
    "        G = 2*(Psi + Gamma.T @ Omega @ Gamma)\n",
    "        F = 2*(Gamma.T @ Omega @ (Phi @ Z0[:nz] - r))\n",
    "        # describe constraints\n",
    "        L = (M @ Gamma + E @ Lambda)\n",
    "        alpha = np.ones((Nc,1))*U_1[0,0]\n",
    "        W = -(E @ alpha + (D + M @ Phi) @ Z0[:nz])\n",
    "        # add soft constraints\n",
    "        Ge[:Nc*nu, :Nc*nu] = G\n",
    "        Fe = np.vstack((F, np.zeros((ne,1))))\n",
    "        Le = np.hstack((L, -np.ones((Nc*2*(nz+nu)+2*nz,ne))))\n",
    "\n",
    "        # solve for optimal U over prediction horizon\n",
    "        opt_result = qp.solve_qp(Ge,Fe,Le,c+W,solver=\"osqp\")\n",
    "        # split optimization result in optimal input and soft bound variable e\n",
    "        dU0[:,0] = opt_result[:Nc*nu]\n",
    "        e = opt_result[-ne]\n",
    "        \n",
    "        # predict states\n",
    "        Z1 = Phi @ Z0[:nz] + Gamma @ dU0\n",
    "        # split extended state up into ouputs and velocity states\n",
    "        Y0, dX1 = decodeState(Z1, nx, ny)\n",
    "        # overwrite previous predicted states and output with new predicted states and output\n",
    "        Y_1[2*ny:,0] = Y0[ny:-ny,0]; dX0[nx:,0] = dX1[:-nx,0] #change the shifting on the output to be consequential\n",
    "        # save previous iteration of U_1\n",
    "        U_1_old = np.copy(U_1)\n",
    "        # determine new X_1 states from known x0 and predicted dX0\n",
    "        for i in range(2,Nc+1):\n",
    "            X_1[(i*nx):(i*nx+nx),:] = dX0[((i-1)*nx):((i-1)*nx+nx),:] + X_1[((i-1)*nx):((i-1)*nx+nx),:]\n",
    "        for i in range(2,Nc+1):\n",
    "            U_1[(i*nu):(i*nu+nu),:] = dU0[((i-1)*nu):((i-1)*nu+nu),:] + U_1[((i-1)*nu):((i-1)*nu+nu),:]\n",
    "\n",
    "        log_comp_t[1, nr_iterations*k + iteration] = log_comp_t[1, nr_iterations*k + iteration] + time.time() - component_start\n",
    "\n",
    "        # stopping condition\n",
    "        if np.linalg.norm(U_1 - U_1_old) < 1e-1:\n",
    "            break\n",
    "    #++++++++++++++++++ end iteration +++++++++++++++++++++++\n",
    "    \n",
    "    # determine input from optimal velocity input\n",
    "    u0 = dU0[:nu,0] + U_1[:nu,0]\n",
    "    # denormalize input\n",
    "    w0 = denorm_input(u0, norm)\n",
    "    # measure output then apply input\n",
    "    system.x = system.f(system.x, w0[0])\n",
    "    q1 = system.h(system.x, w0[0])\n",
    "\n",
    "    # normalize output\n",
    "    y1 = norm_output(q1, norm)\n",
    "\n",
    "    # shift history input and output for encoder\n",
    "    for j in range(nb-1):\n",
    "        uhist[0,j] = uhist[0,j+1]\n",
    "    uhist[0,nb-1] = torch.Tensor(u0)\n",
    "    for j in range(na):\n",
    "        yhist[0,j] = yhist[0,j+1]\n",
    "    yhist[0,na] = torch.Tensor([y1])\n",
    "    # predict state with encoder\n",
    "    x1 = model.encoder(uhist,yhist)\n",
    "\n",
    "    # shift predicted states, input, and output one time step k; and replace with measured/observed values\n",
    "    X_1[:-nx, :] = X_1[nx:, :]; X_1[-nx:, :] = X_1[-2*nx:-nx, :]; X_1[nx:2*nx, :] = x1.detach().numpy().T\n",
    "    U_1[:-nu, :] = U_1[nu:, :]; U_1[-nu:, :] = U_1[-2*nu:-nu, :]; U_1[:nu, :] = u0\n",
    "    Y_1[:-ny, :] = Y_1[ny:, :]; Y_1[-ny:, :] = Y_1[-2*ny:-ny, :]; Y_1[ny:2*ny, :] = y1\n",
    "\n",
    "    # log system signals\n",
    "    log_q[:,k] = q1\n",
    "    log_w[:,k] = w0\n",
    "    log_e[:,k] = e\n",
    "    log_iterations[:,k] = iteration+1\n",
    "    \n",
    "    # print progress\n",
    "    print(\"Sim step: \" + str(k) + \", iterations: \" + str(iteration+1))\n",
    "    \n",
    "#++++++++++++++++++ end simulation step +++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logs from other scripts\n",
    "log_q_nmpc = np.load(\"NonlinearController/experiments/log_q.npy\")\n",
    "log_w_nmpc = np.load(\"NonlinearController/experiments/log_w.npy\")\n",
    "log_u_lpv = np.load(\"NonlinearController/experiments/u_log.npy\")\n",
    "log_y_lpv = np.load(\"NonlinearController/experiments/y_log.npy\")\n",
    "\n",
    "fig1 = plt.figure(figsize=[8.9, 8])\n",
    "\n",
    "start_offset = 4\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(np.arange(nr_sim_steps-start_offset)*dt, log_w[0,start_offset:], label='velocity input')\n",
    "# plt.plot(np.arange(nr_sim_steps-start_offset)*dt, np.hstack((log_u_lpv[1+start_offset:],log_u_lpv[-1])), label='lpv input')\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*w_max, 'r-.')#, label='max')\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*w_min, 'r-.')#, label='min')\n",
    "plt.xlabel(\"time [s]\")\n",
    "plt.ylabel(\"voltage [V]\")\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(np.arange(nr_sim_steps-start_offset)*dt, log_q[0,start_offset:], label='velocity output')\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*q_max[0], 'r-.')#, label='max')\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*q_min[0], 'r-.')#, label='min')\n",
    "# plt.plot(np.arange(nr_sim_steps-start_offset)*dt, np.hstack((log_y_lpv[2+start_offset:],log_y_lpv[-1])), label='lpv output')\n",
    "plt.plot(np.arange(nr_sim_steps-start_offset)*dt, np.hstack((reference[1+start_offset:nr_sim_steps],reference[nr_sim_steps])), 'k--', label='reference', alpha=0.8, linewidth=1)\n",
    "# plt.plot(np.arange(nr_sim_steps-5)*dt, log_q[0,4:-1] - log_q_nmpc[0,5:], label='vel-nmpc')\n",
    "\n",
    "plt.xlabel(\"time [s]\")\n",
    "plt.ylabel(\"angle [rad]\")\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# plt.subplot(2,2,3)\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, log_e[0,:], label='e')\n",
    "# plt.xlabel(\"time [s]\")\n",
    "# plt.ylabel(\"e\")\n",
    "# plt.grid()\n",
    "# plt.legend(loc='upper right')\n",
    "\n",
    "# plt.subplot(2,2,4)\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, log_iterations[0,:], label='iQP')\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*nr_iterations, 'r-.', label='max iter')\n",
    "# plt.xlabel(\"time [s]\")\n",
    "# plt.ylabel(\"iterations\")\n",
    "# plt.grid()\n",
    "# plt.legend(loc='upper right')\n",
    "\n",
    "plt.savefig(\"Figures/offset_free_comparison.svg\")\n",
    "# plt.savefig(\"Figures/velocity_input_states.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_iters = np.split(log_comp_t, nr_sim_steps, axis=1)\n",
    "CT = np.sum(CT_iters[0], axis=1)\n",
    "\n",
    "remove_start = 0\n",
    "S_iter = np.zeros(nr_sim_steps-remove_start)\n",
    "T_iter = np.zeros(nr_sim_steps-remove_start)\n",
    "\n",
    "for i in range(remove_start,nr_sim_steps):\n",
    "    CT = np.sum(CT_iters[i], axis=1)\n",
    "    S_iter[i-remove_start] = CT[1]\n",
    "    T_iter[i-remove_start] = np.sum(CT)\n",
    "\n",
    "Sorted = np.sort(T_iter)\n",
    "# np.max(T_iter)*1000, np.mean(Sorted[int(nr_sim_steps*0.95):])*1000, np.mean(T_iter)*1000, np.std(T_iter)*1000, np.mean(S_iter)*1000 #in ms\n",
    "np.max(T_iter)*1000,  np.mean(T_iter)*1000, np.std(T_iter)*1000, np.mean(S_iter)*1000 #in ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(log_iterations, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=[8.9, 4.0])#['getAB', 'solve', 'overhead', 'sim']\n",
    "data1 = np.trim_zeros(log_comp_t[0,remove_start*nr_iterations:])\n",
    "data2 = np.trim_zeros(log_comp_t[1,remove_start*nr_iterations:])\n",
    "data3 = np.trim_zeros(log_comp_t[2,remove_start*nr_iterations:])\n",
    "data4 = np.trim_zeros(log_comp_t[3,remove_start*nr_iterations:])\n",
    "data = [data1, data2, data3, data4]\n",
    "plt.boxplot(data)\n",
    "plt.xticks([1, 2, 3, 4],  ['getAB', 'solve', 'overhead', 'sim'])\n",
    "plt.grid(axis='y')\n",
    "plt.ylabel(\"time [s]\")\n",
    "plt.xlabel(\"components\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4adf2e6253b261bd4dae3284651a7270092766d2a4e11b51cb3c91db9fd89146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
