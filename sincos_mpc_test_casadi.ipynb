{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from NonlinearController.mpc_utils import *\n",
    "# from NonlinearController.controllers import *\n",
    "from NonlinearController.model_utils import *\n",
    "from NonlinearController.lpv_embedding import *\n",
    "from NonlinearController.systems import UnbalancedDisc, FullUnbalancedDisc\n",
    "from NonlinearController.models import *\n",
    "import matplotlib.pyplot as plt\n",
    "import deepSI\n",
    "import qpsolvers as qp\n",
    "import torch\n",
    "import random\n",
    "from NonlinearController.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################  System  #######################\n",
    "dt = 0.1\n",
    "system = FullUnbalancedDisc(dt=dt, sigma_n=[0.0])\n",
    "system.reset_state()\n",
    "\n",
    "##################  MPC variable specification  #######################\n",
    "Nc=10; nr_iterations = 5; nr_sim_steps = 150\n",
    "\n",
    "w_min = -2; w_max = 2\n",
    "q_min = [-1.,-1.]; q_max = [1.,1.] # augmented with the velocity states\n",
    "w0 = 0; q0 = [0,0]#q0 = [np.sin(0), np.cos(0)]# q0 = np.array([[1,2]]).T\n",
    "\n",
    "# reference_theta = np.ones(nr_sim_steps+Nc)*1.\n",
    "reference_theta = randomLevelReference(nr_sim_steps+Nc, [25,30], [-1.5,1.5])\n",
    "# reference = np.vstack((np.zeros(nr_sim_steps+Nc),reference_theta))\n",
    "reference = np.vstack((np.sin(reference_theta),np.cos(reference_theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 10\n",
    "# u = np.random.uniform(-1,1,N)\n",
    "\n",
    "# system.reset_state()\n",
    "\n",
    "# log_x_Cas = np.zeros((N+1, nx)); log_x_Cas[0,:] = system.x\n",
    "# log_x_SI = np.zeros((N+1, nx)); log_x_SI[0,:] = system.x\n",
    "# log_u = np.zeros((N, nu))\n",
    "\n",
    "# for i in range(N):\n",
    "#     system.x = system.f(system.x, u[i])\n",
    "#     log_x_SI[i+1,:] = system.x\n",
    "\n",
    "#     log_x_Cas[i+1,:] = np.array(f_rk4(log_x_Cas[i,:], u[i]))[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class normalizer():\n",
    "    def __init__(self, y0, ystd, u0, ustd):\n",
    "        self.y0 = y0\n",
    "        self.ystd = ystd\n",
    "\n",
    "        self.u0 = u0\n",
    "        self.ustd = ustd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################  Offline Computation  #######################\n",
    "# Temporary hardcoded variables\n",
    "nx = 2\n",
    "nu = 1\n",
    "ny = 2\n",
    "nz = nx+ny\n",
    "ne = 1\n",
    "\n",
    "# initialize objective function matrices\n",
    "R = np.eye(nu)*0.1; Q = np.zeros((nz,nz)); np.fill_diagonal(Q, [50.,10.,1.,1.]) #Q = np.matrix('10,0,0;0,10,0;0,0,10')# these are user defined\n",
    "Psi = get_Psi(Nc, R)\n",
    "Omega = get_Omega(Nc, Q)\n",
    "# extended objective matrices for soft constraints\n",
    "e_lambda = 1000 # weighting of minimizing e in objective function\n",
    "Ge = np.zeros((Nc*nu+ne,Nc*nu+ne)) \n",
    "Ge[-ne:,-ne:] = e_lambda\n",
    "\n",
    "embedder = CasADi_velocity_lpv_embedder(Nc=Nc, n_stages=3)\n",
    "\n",
    "# normalize initial input and output\n",
    "norm = normalizer(np.array([0.0,0.0]), np.array([1.0,1.0]), 0, 1)#model.norm\n",
    "u0 = norm_input(w0, norm)\n",
    "y0 = norm_output(q0, norm)\n",
    "\n",
    "# determine constraint matrices\n",
    "u_min = norm_input(w_min, norm); u_max = norm_input(w_max, norm)\n",
    "y_min = np.hstack((norm_output(q_min, norm), np.ones(nx)*-100000)); y_max = np.hstack((norm_output(q_max, norm), np.ones(nx)*-100000)) # augmented with the velocity states\n",
    "D, E, M, c = getDEMc(y_min, y_max, u_min, u_max, Nc, nz, nu)\n",
    "Lambda = np.tril(np.ones((Nc,Nc)),0)\n",
    "\n",
    "# initialize observer history input and output\n",
    "# nb = model.nb\n",
    "# uhist = torch.from_numpy(np.tile(u0,nb+1)).T\n",
    "# uhist = torch.ones((1,nb))*u0\n",
    "# na = model.na\n",
    "# yhist = torch.from_numpy(np.tile(y0,na+1)).T\n",
    "# yhist = torch.ones((1,na+1))*y0\n",
    "\n",
    "# initial predicted states, input, and output\n",
    "X_1 = np.tile(np.zeros((1,2)),Nc+1).T\n",
    "U_1 = np.ones((Nc+1)*nu)[np.newaxis].T*u0\n",
    "Y_1 = np.tile(y0[np.newaxis],Nc).T\n",
    "\n",
    "##################  Logging  #######################\n",
    "log_q = np.zeros((ny,nr_sim_steps))\n",
    "log_w = np.zeros((nu,nr_sim_steps))\n",
    "log_e = np.zeros((ne,nr_sim_steps))\n",
    "log_iterations = np.zeros((1,nr_sim_steps))\n",
    "log_comp_t = np.zeros((4, nr_sim_steps*nr_iterations))\n",
    "\n",
    "offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################  Online Computation  #######################\n",
    "\n",
    "#++++++++++++++++++ start simulation step +++++++++++++++++++++++\n",
    "for k in range(nr_sim_steps):\n",
    "    # extend normalized reference to form of extended state\n",
    "    r = extendReference((reference[:,k:k+Nc] - norm.y0[np.newaxis].T)/norm.ystd[np.newaxis].T, nx, ny, Nc)\n",
    "    \n",
    "    #++++++++++++++++++ start iteration +++++++++++++++++++++++\n",
    "    for iteration in range(nr_iterations):\n",
    "        # determine predicted velocity states and output\n",
    "        dX0 = differenceVector(X_1, nx)\n",
    "        dU0 = differenceVector(U_1, nu)\n",
    "        # determine extended state from predicted output and velocity states\n",
    "        Z0 = extendState(Y_1, dX0, nx, ny, Nc)\n",
    "\n",
    "        # determine lpv state space dependencies\n",
    "        list_A, list_B, list_C = embedder(X_1, U_1)\n",
    "        list_ext_A, list_ext_B, list_ext_C = extendABC(list_A, list_B, list_C, nx, ny, nu, Nc)\n",
    "\n",
    "        # describe optimization problem\n",
    "        Phi = get_Phi(list_ext_A, Nc, nz)\n",
    "        Gamma = get_Gamma(list_ext_A, list_ext_B, Nc, nz, nu)\n",
    "        G = 2*(Psi + Gamma.T @ Omega @ Gamma)\n",
    "        F = 2*(Gamma.T @ Omega @ (Phi @ Z0[:nz] - r))\n",
    "        # describe constraints\n",
    "        L = (M @ Gamma + E @ Lambda)\n",
    "        alpha = np.ones((Nc,1))*U_1[0,0]\n",
    "        W = -(E @ alpha + (D + M @ Phi) @ Z0[:nz])\n",
    "        # add soft constraints\n",
    "        Ge[:Nc*nu, :Nc*nu] = G\n",
    "        Fe = np.vstack((F, np.zeros((ne,1))))\n",
    "        Le = np.hstack((L, -np.ones((Nc*2*(nz+nu)+2*nz,ne))))\n",
    "\n",
    "        # solve for optimal U over prediction horizon\n",
    "        # opt_result = qp.solve_qp(Ge,Fe,Le,c+W,solver=\"osqp\")\n",
    "        opt_result = qp.solve_qp(Ge,Fe,solver=\"osqp\")\n",
    "        # split optimization result in optimal input and soft bound variable e\n",
    "        dU0[:,0] = opt_result[:Nc*nu]\n",
    "        e = opt_result[-ne]\n",
    "        \n",
    "        # predict states\n",
    "        Z1 = Phi @ Z0[:nz] + Gamma @ dU0\n",
    "        # split extended state up into ouputs and velocity states\n",
    "        Y0, dX1 = decodeState(Z1, nx, ny, Nc)\n",
    "        # overwrite previous predicted states and output with new predicted states and output\n",
    "        Y_1[2*ny:,0] = Y0[ny:-ny,0]; dX0[nx:,0] = dX1[:-nx,0] #change the shifting on the output to be consequential\n",
    "        # save previous iteration of U_1\n",
    "        U_1_old = np.copy(U_1)\n",
    "        # determine new X_1 states from known x0 and predicted dX0\n",
    "        for i in range(2,Nc+1):\n",
    "            X_1[(i*nx):(i*nx+nx),:] = dX0[((i-1)*nx):((i-1)*nx+nx),:] + X_1[((i-1)*nx):((i-1)*nx+nx),:]\n",
    "        for i in range(2,Nc+1):\n",
    "            U_1[(i*nu):(i*nu+nu),:] = dU0[((i-1)*nu):((i-1)*nu+nu),:] + U_1[((i-1)*nu):((i-1)*nu+nu),:]\n",
    "\n",
    "        # stopping condition\n",
    "        if np.linalg.norm(U_1 - U_1_old) < 1e0:\n",
    "            break\n",
    "    #++++++++++++++++++ end iteration +++++++++++++++++++++++\n",
    "    \n",
    "    # determine input from optimal velocity input\n",
    "    u0 = dU0[:nu,0] + U_1[:nu,0]\n",
    "    # denormalize input\n",
    "    w0 = denorm_input(u0, norm)\n",
    "    # measure output then apply input\n",
    "    system.x = system.f(system.x, w0[0])\n",
    "    omega1, theta1 = system.h(system.x, w0[0])\n",
    "    q1 = np.array((np.sin(theta1), np.cos(theta1)))\n",
    "    # normalize output\n",
    "    y1 = norm_output(q1, norm)\n",
    "\n",
    "    # shift history input and output for encoder\n",
    "    # for j in range(nb-1):\n",
    "    #     uhist[0,j] = uhist[0,j+1]\n",
    "    # uhist[0,nb-1] = torch.Tensor(u0)\n",
    "    # for j in range(na):\n",
    "    #     yhist[0,j] = yhist[0,j+1]\n",
    "    # yhist[0,na] = torch.Tensor([y1])\n",
    "    # # predict state with encoder\n",
    "    # x1 = model.encoder(uhist,yhist)\n",
    "    x1 = np.vstack((omega1, theta1))\n",
    "\n",
    "    # shift predicted states, input, and output one time step k; and replace with measured/observed values\n",
    "    X_1[:-nx, :] = X_1[nx:, :]; X_1[-nx:, :] = X_1[-2*nx:-nx, :]; X_1[nx:2*nx, :] = x1\n",
    "    U_1[:-nu, :] = U_1[nu:, :]; U_1[-nu:, :] = U_1[-2*nu:-nu, :]; U_1[:nu, :] = u0\n",
    "    Y_1[:-ny, :] = Y_1[ny:, :]; Y_1[-ny:, :] = Y_1[-2*ny:-ny, :]; Y_1[ny:2*ny, :] = y1[np.newaxis].T\n",
    "\n",
    "    # log system signals\n",
    "    log_q[:,k] = q1\n",
    "    log_w[:,k] = w0\n",
    "    log_e[:,k] = e\n",
    "    log_iterations[:,k] = iteration+1\n",
    "    \n",
    "    # print progress\n",
    "    # print(\"Sim step: \" + str(k) + \", iterations: \" + str(iteration+1))\n",
    "    \n",
    "#++++++++++++++++++ end simulation step +++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logs from other scripts\n",
    "log_q_nmpc = np.load(\"NonlinearController/experiments/log_q.npy\")\n",
    "log_w_nmpc = np.load(\"NonlinearController/experiments/log_w.npy\")\n",
    "log_u_lpv = np.load(\"NonlinearController/experiments/u_log.npy\")\n",
    "log_y_lpv = np.load(\"NonlinearController/experiments/y_log.npy\")\n",
    "\n",
    "fig1 = plt.figure(figsize=[16, 8])\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(np.arange(nr_sim_steps)*dt, log_w[0,:], label='velocity input')\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, np.hstack((log_u_lpv[1:],log_u_lpv[-1])), label='lpv input')\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*w_max, 'r-.')#, label='max')\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*w_min, 'r-.')#, label='min')\n",
    "plt.xlabel(\"time [s]\")\n",
    "plt.ylabel(\"voltage [V]\")\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(np.arange(nr_sim_steps)*dt, log_q[0,:], label='velocity output')\n",
    "plt.plot(np.arange(nr_sim_steps)*dt, np.hstack((reference[0,1:nr_sim_steps],reference[0,nr_sim_steps])), '--', label='reference')\n",
    "plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*q_max[0], 'r-.')#, label='max')\n",
    "plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*q_min[0], 'r-.')#, label='min')\n",
    "plt.xlabel(\"time [s]\")\n",
    "plt.ylabel(\"sin theta\")\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(np.arange(nr_sim_steps)*dt, log_q[1,:], label='velocity output')\n",
    "plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*q_max[1], 'r-.')#, label='max')\n",
    "plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*q_min[1], 'r-.')#, label='min')\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, np.hstack((log_y_lpv[2:],log_y_lpv[-1])), label='lpv output')\n",
    "plt.plot(np.arange(nr_sim_steps)*dt, np.hstack((reference[1,1:nr_sim_steps],reference[1,nr_sim_steps])), '--', label='reference')\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, log_q[0,:] - log_q_nmpc[0,:], label='vel-nmpc')\n",
    "plt.xlabel(\"time [s]\")\n",
    "plt.ylabel(\"cos theta\")\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# plt.subplot(2,2,3)\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, log_e[0,:], label='e')\n",
    "# plt.xlabel(\"time [s]\")\n",
    "# plt.ylabel(\"e\")\n",
    "# plt.grid()\n",
    "# plt.legend(loc='upper right')\n",
    "\n",
    "# plt.subplot(2,2,4)\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, log_iterations[0,:], label='iQP')\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*nr_iterations, 'r-.', label='max iter')\n",
    "# plt.xlabel(\"time [s]\")\n",
    "# plt.ylabel(\"iterations\")\n",
    "# plt.grid()\n",
    "# plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4adf2e6253b261bd4dae3284651a7270092766d2a4e11b51cb3c91db9fd89146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
