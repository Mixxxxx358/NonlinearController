{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Jul 20 01:18:13 PM: Encountered unexpected exception importing solver PROXQP:\n",
      "ImportError('DLL load failed while importing instructionset: The specified module could not be found.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from NonlinearController.mpc_utils import *\n",
    "from NonlinearController.controllers import *\n",
    "from NonlinearController.model_utils import *\n",
    "from NonlinearController.lpv_embedding import *\n",
    "from NonlinearController.systems import UnbalancedDisc, ReversedSinCosUnbalancedDisc, SinCosUnbalancedDisc\n",
    "import deepSI\n",
    "import qpsolvers as qp\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "from NonlinearController.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cvxopt', 'cvxpy', 'ecos', 'osqp', 'quadprog', 'scs']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qp.available_solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class sincos_output_net(nn.Module):\n",
    "    def __init__(self, nx, ny, nu=-1, n_nodes_per_layer=64, n_hidden_layers=2, activation=nn.Tanh):\n",
    "        super(sincos_output_net, self).__init__()\n",
    "        from deepSI.utils import simple_res_net\n",
    "        self.ny = tuple() if ny is None else ((ny,) if isinstance(ny,int) else ny)\n",
    "        self.feedthrough = nu!=-1\n",
    "        if self.feedthrough:\n",
    "            self.nu = tuple() if nu is None else ((nu,) if isinstance(nu,int) else nu)\n",
    "            net_in = nx + np.prod(self.nu, dtype=int)\n",
    "        else:\n",
    "            net_in = nx\n",
    "        self.net = simple_res_net(n_in=net_in, n_out=np.prod((1,),dtype=int), n_nodes_per_layer=n_nodes_per_layer, \\\n",
    "            n_hidden_layers=n_hidden_layers, activation=activation)\n",
    "\n",
    "    def forward(self, x, u=None):\n",
    "        xu = x\n",
    "        xu = self.net(xu).view(*((x.shape[0],)+(1,)))\n",
    "        y = torch.cat([torch.sin(xu), torch.cos(xu)], dim=1)\n",
    "        return y\n",
    "    \n",
    "# change input from sin cos to arctan2 of sin cos.\n",
    "    #!!! There is probably a problem with the sin and cos being normalized at the arctan2\n",
    "class arctan2_encoder_net(nn.Module):\n",
    "    def __init__(self, nb, nu, na, ny, nx, n_nodes_per_layer=64, n_hidden_layers=2, activation=nn.Tanh):\n",
    "        super(arctan2_encoder_net, self).__init__()\n",
    "        from deepSI.utils import simple_res_net\n",
    "        self.nu = tuple() if nu is None else ((nu,) if isinstance(nu,int) else nu)\n",
    "        self.ny = tuple() if ny is None else ((ny,) if isinstance(ny,int) else ny)\n",
    "        self.net = simple_res_net(n_in=nb*np.prod(self.nu,dtype=int) + na*np.prod((1,),dtype=int), \\\n",
    "            n_out=nx, n_nodes_per_layer=n_nodes_per_layer, n_hidden_layers=n_hidden_layers, activation=activation)\n",
    "\n",
    "    def forward(self, upast, ypast):\n",
    "        ypast = torch.mul(torch.atan2(ypast[:,:,0],ypast[:,:,1]),0.5)\n",
    "        net_in = torch.cat([upast.view(upast.shape[0],-1),ypast.view(ypast.shape[0],-1)],axis=1)\n",
    "        return self.net(net_in)\n",
    "\n",
    "class SinCos_encoder(deepSI.fit_systems.SS_encoder_general):\n",
    "    def __init__(self, nx=10, na=20, nb=20, na_right=0, nb_right=0, e_net_kwargs={}, f_net_kwargs={}, h_net_kwargs={}):\n",
    "        super(SinCos_encoder, self).__init__(nx=nx, na=na, nb=nb, na_right=na_right, nb_right=nb_right, e_net_kwargs=e_net_kwargs, f_net_kwargs=f_net_kwargs, h_net_kwargs=h_net_kwargs)\n",
    "        self.h_net = sincos_output_net\n",
    "        # self.e_net = arctan2_encoder_net\n",
    "        # self.f_net = sincos_state_net\n",
    "\n",
    "    def init_nets(self, nu, ny): # a bit weird\n",
    "        na_right = self.na_right if hasattr(self,'na_right') else 0\n",
    "        nb_right = self.nb_right if hasattr(self,'nb_right') else 0\n",
    "        self.encoder = self.e_net(nb=(self.nb+nb_right), nu=nu, na=(self.na+na_right), ny=ny, nx=self.nx, **self.e_net_kwargs)\n",
    "        self.fn =      self.f_net(nx=self.nx, nu=nu,                                **self.f_net_kwargs)\n",
    "        # self.hn =      nn.Identity(self.nx)\n",
    "        self.hn =      self.h_net(nx=self.nx, ny=ny,                            **self.h_net_kwargs)\n",
    "\n",
    "    def init_model(self, sys_data=None, nu=-1, ny=-1, device='cpu', auto_fit_norm=True, optimizer_kwargs={}, parameters_optimizer_kwargs={}, scheduler_kwargs={}):\n",
    "        '''This function set the nu and ny, inits the network, moves parameters to device, initilizes optimizer and initilizes logging parameters'''\n",
    "        if sys_data==None:\n",
    "            assert nu!=-1 and ny!=-1, 'either sys_data or (nu and ny) should be provided'\n",
    "            self.nu, self.ny = nu, ny\n",
    "        else:\n",
    "            self.nu, self.ny = sys_data.nu, sys_data.ny\n",
    "            # if auto_fit_norm:\n",
    "            #     self.norm.fit(sys_data)\n",
    "            self.norm.ustd = 1.8\n",
    "            self.norm.y0 = np.array([0.0,0.0])\n",
    "            self.norm.ystd = np.array([1.0,1.0])\n",
    "            print(self.norm.ystd)\n",
    "        self.init_nets(self.nu, self.ny)\n",
    "        self.to_device(device=device)\n",
    "        parameters_and_optim = [{**item,**parameters_optimizer_kwargs.get(name,{})} for name,item in self.parameters_with_names.items()]\n",
    "        self.optimizer = self.init_optimizer(parameters_and_optim, **optimizer_kwargs)\n",
    "        self.scheduler = self.init_scheduler(**scheduler_kwargs)\n",
    "        self.bestfit = float('inf')\n",
    "        self.Loss_val, self.Loss_train, self.batch_id, self.time, self.epoch_id = np.array([]), np.array([]), np.array([]), np.array([]), np.array([])\n",
    "        self.init_model_done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################  System  #######################\n",
    "dt = 0.1\n",
    "# system = UnbalancedDisc(dt=dt, sigma_n=[0.014])\n",
    "system = SinCosUnbalancedDisc(dt=dt, sigma_n=[0.0])\n",
    "system.reset_state()\n",
    "\n",
    "# system.x = system.f(system.x, 0.5)\n",
    "# for i in range(500):\n",
    "#     system.x = system.f(system.x, 0.0)\n",
    "\n",
    "##################  MPC variable specification  #######################\n",
    "# model = deepSI.load_system(\"NonlinearController/trained_models/unbalanced/ObserverUnbalancedDisk_dt01_nab_4_SNR_30_e250\")\n",
    "model = deepSI.load_system(\"NonlinearController/trained_models/sincos/sincosNet_dt0_1_e100_b1000_nf15_amp2_3_sn0_014\")\n",
    "Nc=10; nr_iterations = 1; nr_sim_steps = 100\n",
    "\n",
    "w_min = -4; w_max = -w_min\n",
    "q_min = [-1., -1.]; q_max = [1., 1.]\n",
    "w0 = 0; q0 = [np.sin(0), np.cos(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference_theta = np.ones(nr_sim_steps+Nc)*(-1.)\n",
    "reference_theta = randomLevelReference(nr_sim_steps+Nc, [25,30], [-2,2])\n",
    "reference = np.vstack((np.sin(reference_theta),np.cos(reference_theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.norm.y0 = np.array([0.0,0.0])\n",
    "model.norm.ystd = np.array([1.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################  Offline Computation  #######################\n",
    "nx = model.nx\n",
    "nu = model.nu if model.nu is not None else 1\n",
    "ny = model.ny if model.ny is not None else 1\n",
    "nz = nx+ny\n",
    "ne = 1\n",
    "\n",
    "# initialize objective function matrices\n",
    "P = np.eye(ny)*0.01\n",
    "Q1 = np.zeros((ny,ny)); np.fill_diagonal(Q1, [50,50])\n",
    "Q2 = np.zeros((nz,nz)); Q2[ny:,ny:] = np.eye(nx)\n",
    "Omega1 = get_Omega(Nc, Q1)\n",
    "Omega2 = get_Omega(Nc, Q2)\n",
    "\n",
    "R = np.eye(nu)*1;# Q = np.zeros((nz,nz)); np.fill_diagonal(Q, [200.,200.,1.,1.]) #Q = np.matrix('10,0,0;0,10,0;0,0,10')# these are user defined\n",
    "Psi = get_Psi(Nc, R)\n",
    "# extended objective matrices for soft constraints\n",
    "e_lambda = 100 # weighting of minimizing e in objective function\n",
    "Ge = np.zeros((Nc*nu+ne,Nc*nu+ne)) \n",
    "Ge[-ne:,-ne:] = e_lambda\n",
    "\n",
    "embedder = velocity_lpv_embedder_autograd(model, Nc, n_stages=20)\n",
    "\n",
    "# normalize initial input and output\n",
    "norm = model.norm\n",
    "u0 = norm_input(w0, norm)\n",
    "y0 = norm_output(q0, norm)\n",
    "\n",
    "# initialize observer history input and output\n",
    "nb = model.nb\n",
    "uhist = torch.ones((1,nb))*u0\n",
    "na = model.na\n",
    "# yhist = torch.ones((1,na+1))*y0\n",
    "yhist = torch.Tensor(y0[np.newaxis].T).repeat(1,na+1)[None,:,:]\n",
    "\n",
    "# initial predicted states, input, and output\n",
    "X_1 = np.tile(model.encoder(uhist,yhist).detach().numpy(),Nc+2).T\n",
    "U_1 = np.ones((Nc+1)*nu)[np.newaxis].T*u0\n",
    "# Y_1 = np.ones((Nc)*ny)[np.newaxis].T *y0\n",
    "Y_1 = np.tile(y0[np.newaxis],Nc).T\n",
    "\n",
    "# determine constraint matrices\n",
    "u_min = norm_input(w_min, norm); u_max = norm_input(w_max, norm)\n",
    "y_min = np.hstack((norm_output(q_min, norm), np.ones(nx)*-10000)); y_max = np.hstack((norm_output(q_max, norm), np.ones(nx)*10000)) # augmented with the velocity states\n",
    "D, E, M, c = getDEMc(y_min, y_max, u_min, u_max, Nc, nz, nu)\n",
    "Lambda = np.tril(np.ones((Nc,Nc)),0)\n",
    "\n",
    "##################  Logging  #######################\n",
    "log_q = np.zeros((ny,nr_sim_steps))\n",
    "log_w = np.zeros((nu,nr_sim_steps))\n",
    "log_e = np.zeros((ne,nr_sim_steps))\n",
    "log_iterations = np.zeros((1,nr_sim_steps))\n",
    "log_comp_t = np.zeros((4, nr_sim_steps*nr_iterations))\n",
    "\n",
    "offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################  Online Computation  #######################\n",
    "\n",
    "#++++++++++++++++++ start simulation step +++++++++++++++++++++++\n",
    "for k in range(nr_sim_steps):\n",
    "    # extend normalized reference to form of extended state\n",
    "    \n",
    "    r = extendReference((reference[:,k:k+Nc] - norm.y0[np.newaxis].T)/norm.ystd[np.newaxis].T, 0, ny, Nc)\n",
    "    \n",
    "    #++++++++++++++++++ start iteration +++++++++++++++++++++++\n",
    "    for iteration in range(nr_iterations):\n",
    "        component_start = time.time()\n",
    "        \n",
    "        # determine predicted velocity states and output\n",
    "        dX0 = differenceVector(X_1[:-nx], nx)\n",
    "        dU0 = differenceVector(U_1, nu)\n",
    "        # determine extended state from predicted output and velocity states\n",
    "        Z0 = extendState(Y_1, dX0, nx, ny, Nc)\n",
    "\n",
    "        Z0 = extendState(Y_1, dX0, nx, ny, Nc)\n",
    "\n",
    "        # determine lpv state space dependencies\n",
    "        list_A, list_B, list_C = embedder(X_1, U_1)\n",
    "        list_ext_A, list_ext_B, list_ext_C = extendABC(list_A, list_B, list_C, nx, ny, nu, Nc)\n",
    "\n",
    "        # describe optimization problem\n",
    "        c_terminal = np.vstack((r[-ny:,:],np.zeros((nx,1))))\n",
    "        M_terminal = np.zeros((nx+ny,ny)); M_terminal[:ny,:] = np.eye(ny)\n",
    "        E_terminal = np.zeros((nx+ny,nx)); E_terminal[ny:,:] = np.eye(nx)\n",
    "        Sy = np.hstack((np.zeros((ny,(Nc-1)*ny)),np.eye(ny)))\n",
    "        # Sz = np.hstack((np.zeros((nz,(Nc-1)*nz)),np.diag(np.hstack((np.zeros(ny),np.ones(nx))))))\n",
    "        Sx = np.hstack((np.zeros((nx,(Nc-1)*nz+ny)),np.eye(nx)))\n",
    "        Z = getZ(list_ext_C,Nc,ny,nz)\n",
    "        Phi = get_Phi(list_ext_A, Nc, nz)\n",
    "        Gamma = get_Gamma(list_ext_A, list_ext_B, Nc, nz, nu)\n",
    "\n",
    "        Phi = get_Phi(list_ext_A, Nc, nz)\n",
    "        Gamma = get_Gamma(list_ext_A, list_ext_B, Nc, nz, nu)\n",
    "        G = 2*(Gamma.T @ (Z.T @ (Omega1 + Sy.T @ P @ Sy) @ Z + Omega2) @ Gamma + Psi)\n",
    "        F = 2*(Gamma.T @ (Z.T @ (Omega1 @ (Z @ Phi @ Z0[:nz] - r) + Sy.T @ P @ (Sy @ Z @ Phi @ Z0[:nz] - r[-ny:])) + Omega2 @ Phi @ Z0[:nz]))\n",
    "        # G = 2*(Psi + Gamma.T @ Omega @ Gamma)\n",
    "        # F = 2*(Gamma.T @ Omega @ (Phi @ Z0[:nz] - r))\n",
    "\n",
    "        # describe constraints\n",
    "        L = (M @ Gamma + E @ Lambda)\n",
    "        alpha = np.ones((Nc,1))*U_1[0,0]\n",
    "        W = -(E @ alpha + (D + M @ Phi) @ Z0[:nz])\n",
    "\n",
    "        # add soft constraints\n",
    "        Ge[:Nc*nu, :Nc*nu] = G\n",
    "        Fe = np.vstack((F, np.zeros((ne,1))))\n",
    "        Le = np.hstack((L, -np.ones((Nc*2*(nz+nu)+2*nz,ne))))\n",
    "\n",
    "        # add equality constraints\n",
    "        A = (E_terminal @ Sx) @ Gamma\n",
    "        Ae = np.hstack((A,np.zeros((nz,1))))\n",
    "        b = c_terminal-(E_terminal @ Sx) @ Phi @ Z0[:nz]\n",
    "\n",
    "        # solve for optimal U over prediction horizon\n",
    "        opt_result = qp.solve_qp(Ge,Fe,Le,c+W,solver=\"osqp\",initvals=np.hstack((dU0[:,0],0)))\n",
    "        # opt_result = qp.solve_qp(Ge,Fe,solver=\"osqp\",initvals=np.hstack((dU0[:,0],0)))\n",
    "        # split optimization result in optimal input and soft bound variable e\n",
    "        dU0[:,0] = opt_result[:Nc*nu]\n",
    "        e = opt_result[-ne]\n",
    "        \n",
    "        # predict states\n",
    "        Z1 = Phi @ Z0[:nz] + Gamma @ dU0\n",
    "        # split extended state up into ouputs and velocity states\n",
    "        Y0, dX1 = decodeState(Z1, nx, ny, Nc)\n",
    "        # overwrite previous predicted states and output with new predicted states and output\n",
    "        Y_1[2*ny:,0] = Y0[ny:-ny,0]; dX0[nx:,0] = dX1[:-nx,0] #change the shifting on the output to be consequential\n",
    "        # save previous iteration of U_1\n",
    "        U_1_old = np.copy(U_1)\n",
    "        # determine new X_1 states from known x0 and predicted dX0\n",
    "        for i in range(2,Nc+1):\n",
    "            X_1[(i*nx):(i*nx+nx),:] = dX0[((i-1)*nx):((i-1)*nx+nx),:] + X_1[((i-1)*nx):((i-1)*nx+nx),:]\n",
    "        for i in range(2,Nc+1):\n",
    "            U_1[(i*nu):(i*nu+nu),:] = dU0[((i-1)*nu):((i-1)*nu+nu),:] + U_1[((i-1)*nu):((i-1)*nu+nu),:]\n",
    "\n",
    "        log_comp_t[1, nr_iterations*k + iteration] = log_comp_t[1, nr_iterations*k + iteration] + time.time() - component_start\n",
    "\n",
    "        # stopping condition\n",
    "        if np.linalg.norm(U_1 - U_1_old) < 1e-2:\n",
    "            break\n",
    "    #++++++++++++++++++ end iteration +++++++++++++++++++++++\n",
    "    \n",
    "    # determine input from optimal velocity input\n",
    "    u0 = dU0[:nu,0] + U_1[:nu,0]\n",
    "    # denormalize input\n",
    "    w0 = denorm_input(u0, norm)\n",
    "    # measure output then apply input\n",
    "    system.x = system.f(system.x, w0[0])\n",
    "    q1 = system.h(system.x, w0[0])\n",
    "\n",
    "    # normalize output\n",
    "    y1 = norm_output(q1, norm)\n",
    "\n",
    "    # shift history input and output for encoder\n",
    "    for j in range(nb-1):\n",
    "        uhist[0,j] = uhist[0,j+1]\n",
    "    uhist[0,nb-1] = torch.Tensor(u0)\n",
    "    for j in range(na):\n",
    "        yhist[0,:,j] = yhist[0,:,j+1]\n",
    "    yhist[0,:,na] = torch.Tensor(y1)\n",
    "    # predict state with encoder\n",
    "    x1 = model.encoder(uhist,yhist)\n",
    "\n",
    "    # shift predicted states, input, and output one time step k; and replace with measured/observed values\n",
    "    X_1[:-nx, :] = X_1[nx:, :]; X_1[-nx:, :] = X_1[-2*nx:-nx, :]; X_1[nx:2*nx, :] = x1.detach().numpy().T\n",
    "    U_1[:-nu, :] = U_1[nu:, :]; U_1[-nu:, :] = U_1[-2*nu:-nu, :]; U_1[:nu, :] = u0\n",
    "    Y_1[:-ny, :] = Y_1[ny:, :]; Y_1[-ny:, :] = Y_1[-2*ny:-ny, :]; Y_1[ny:2*ny, :] = y1[np.newaxis].T\n",
    "\n",
    "    # log system signals\n",
    "    log_q[:,k] = q1\n",
    "    log_w[:,k] = w0\n",
    "    log_e[:,k] = e\n",
    "    log_iterations[:,k] = iteration+1\n",
    "    \n",
    "    # print progress\n",
    "    print(\"Sim step: \" + str(k) + \", iterations: \" + str(iteration+1))\n",
    "    \n",
    "#++++++++++++++++++ end simulation step +++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logs from other scripts\n",
    "# log_q_nmpc = np.load(\"NonlinearController/experiments/log_q.npy\")\n",
    "# log_w_nmpc = np.load(\"NonlinearController/experiments/log_w.npy\")\n",
    "# log_u_lpv = np.load(\"NonlinearController/experiments/u_log.npy\")\n",
    "# log_y_lpv = np.load(\"NonlinearController/experiments/y_log.npy\")\n",
    "\n",
    "# fig1 = plt.figure(figsize=[8.9, 8])\n",
    "fig1 = plt.figure(figsize=[14, 11])\n",
    "\n",
    "start_offset = 0\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(np.arange(nr_sim_steps-start_offset)*dt, log_w[0,start_offset:], label='velocity input')\n",
    "# plt.plot(np.arange(nr_sim_steps-start_offset)*dt, np.hstack((log_u_lpv[1+start_offset:],log_u_lpv[-1])), label='lpv input')\n",
    "plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*w_max, 'r-.')#, label='max')\n",
    "plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*w_min, 'r-.')#, label='min')\n",
    "# # plt.xlabel(\"time [s]\")\n",
    "plt.ylabel(\"voltage [V]\")\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(np.arange(nr_sim_steps-start_offset)*dt, log_q[0,start_offset:], label='velocity output')\n",
    "plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*q_max[0], 'r-.')#, label='max')\n",
    "plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*q_min[0], 'r-.')#, label='min')\n",
    "# plt.plot(np.arange(nr_sim_steps-start_offset)*dt, np.hstack((log_y_lpv[2+start_offset:],log_y_lpv[-1])), label='lpv output')\n",
    "plt.plot(np.arange(nr_sim_steps-start_offset)*dt, np.hstack((reference[0,1+start_offset:nr_sim_steps],reference[0,nr_sim_steps])), 'k--', label='reference', alpha=0.8, linewidth=1)\n",
    "# plt.plot(np.arange(nr_sim_steps-5)*dt, log_q[0,4:-1] - log_q_nmpc[0,5:nr_sim_steps], label='vel-nmpc')\n",
    "plt.xlabel(\"time [s]\")\n",
    "plt.ylabel(\"sin angle\")\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(np.arange(nr_sim_steps-start_offset)*dt, log_q[1,start_offset:], label='velocity output')\n",
    "plt.plot(np.arange(nr_sim_steps-start_offset)*dt, np.hstack((reference[1,1+start_offset:nr_sim_steps],reference[1,nr_sim_steps])), 'k--', label='reference', alpha=0.8, linewidth=1)\n",
    "plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*q_max[0], 'r-.')#, label='max')\n",
    "plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*q_min[0], 'r-.')#, label='min')\n",
    "plt.xlabel(\"time [s]\")\n",
    "plt.ylabel(\"cos angle\")\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# plt.subplot(2,2,3)\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, log_e[0,:], label='e')\n",
    "# plt.xlabel(\"time [s]\")\n",
    "# plt.ylabel(\"e\")\n",
    "# plt.grid()\n",
    "# plt.legend(loc='upper right')\n",
    "\n",
    "# plt.subplot(2,2,4)\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, log_iterations[0,:], label='iQP')\n",
    "# plt.plot(np.arange(nr_sim_steps)*dt, np.ones(nr_sim_steps)*nr_iterations, 'r-.', label='max iter')\n",
    "# plt.xlabel(\"time [s]\")\n",
    "# plt.ylabel(\"iterations\")\n",
    "# plt.grid()\n",
    "# plt.legend(loc='upper right')\n",
    "\n",
    "# plt.savefig(\"Figures/offset_free_comparison.svg\")\n",
    "# plt.savefig(\"Figures/velocity_input_states.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_iters = np.split(log_comp_t, nr_sim_steps, axis=1)\n",
    "CT = np.sum(CT_iters[0], axis=1)\n",
    "\n",
    "remove_start = 0\n",
    "S_iter = np.zeros(nr_sim_steps-remove_start)\n",
    "T_iter = np.zeros(nr_sim_steps-remove_start)\n",
    "\n",
    "for i in range(remove_start,nr_sim_steps):\n",
    "    CT = np.sum(CT_iters[i], axis=1)\n",
    "    S_iter[i-remove_start] = CT[1]\n",
    "    T_iter[i-remove_start] = np.sum(CT)\n",
    "\n",
    "Sorted = np.sort(T_iter)\n",
    "# np.max(T_iter)*1000, np.mean(Sorted[int(nr_sim_steps*0.95):])*1000, np.mean(T_iter)*1000, np.std(T_iter)*1000, np.mean(S_iter)*1000 #in ms\n",
    "np.max(T_iter)*1000,  np.mean(T_iter)*1000, np.std(T_iter)*1000, np.mean(S_iter)*1000 #in ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(log_iterations, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=[8.9, 4.0])#['getAB', 'solve', 'overhead', 'sim']\n",
    "data1 = np.trim_zeros(log_comp_t[0,remove_start*nr_iterations:])\n",
    "data2 = np.trim_zeros(log_comp_t[1,remove_start*nr_iterations:])\n",
    "data3 = np.trim_zeros(log_comp_t[2,remove_start*nr_iterations:])\n",
    "data4 = np.trim_zeros(log_comp_t[3,remove_start*nr_iterations:])\n",
    "data = [data1, data2, data3, data4]\n",
    "plt.boxplot(data)\n",
    "plt.xticks([1, 2, 3, 4],  ['getAB', 'solve', 'overhead', 'sim'])\n",
    "plt.grid(axis='y')\n",
    "plt.ylabel(\"time [s]\")\n",
    "plt.xlabel(\"components\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4adf2e6253b261bd4dae3284651a7270092766d2a4e11b51cb3c91db9fd89146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
